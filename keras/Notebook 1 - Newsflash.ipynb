{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Keras and verify that the TensorFlow backend is set as the default.\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying newswires: a multi-class classification example\n",
    "\n",
    "This notebook contains code samples that have been adapted from Francois Chollet's Deep Learning With Python.\n",
    "\n",
    "----\n",
    "In this notebook we are going to introduce how to build a [`Sequential`](https://keras.io/getting-started/sequential-model-guide/) model using [`Dense`](https://keras.io/layers/core/) layers. A Sequential model is a linear stack of layers with a single input and output. A Dense layer is a fully connected layer in your model. We are also going to introduce the following APIs:\n",
    "* `compile`\n",
    "* `fit`\n",
    "* `evaluate`\n",
    "* `predict`\n",
    "\n",
    "We will also introduce `callbacks` and how you can use them as part of model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "To get familiar with Keras APIs we we going to build a network to classify Reuters newswires into 46 different mutually-exclusive topics. Since we have many \n",
    "classes, this problem is an instance of \"multi-class classification\", and since each data point should be classified into only one \n",
    "category, the problem is more specifically an instance of \"single-label, multi-class classification\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "\n",
    "We will be working with the _Reuters dataset_, a set of short newswires and their topics, published by Reuters in 1986. It's a very simple, \n",
    "widely used toy dataset for text classification. There are 46 different topics; some topics are more represented than others, but each topic has at least 10 examples in the training set.\n",
    "\n",
    "A number of datasets come packaged as part of Keras. A few examples of these Datasets can be found [here](https://keras.io/datasets/). Some example datasets are IMDB, MNIST, CIFAR10 etc. The _Reuters dataset_ also comes prepackaged with Keras. Lets take a look at what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 12s 6us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `num_words=10000` restricts the data to the 10,000 most frequently occurring words found in the data.\n",
    "\n",
    "We have 8,982 training examples and 2,246 test examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example is a list of integers (word indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how you can decode it back to words, in case you are curious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 5s 9us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "# Note that our indices were offset by 3\n",
    "# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we limit the number of word index dictionary to the first 10000 words, there is a chance\n",
    "that the newswire will have words that do not have an index associated with it. This is what the ? symbol\n",
    "represents in the above newswire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label associated with an example is an integer between 0 and 45: a topic index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "We can vectorize the data with the exact same code as in our previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To vectorize the labels, there are two possibilities: we could just cast the label list as an integer tensor, or we could use a \"one-hot\" \n",
    "encoding. One-hot encoding of our labels consists in embedding each label as an all-zero vector with a 1 in the place of the label index. You can do this using a built-in Keras function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our network\n",
    "\n",
    "\n",
    "In this topic classification problem we are trying to classify short snippets of text. The difference between a binary classification problem and this one is that the number of output class is 46 i.e the dimensionality of the output space is much larger. (A binary classification problem is one in which there are two possible output clases.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Sequential model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Instantiate a Sequential Model\n",
    "model = models.Sequential()\n",
    "# Add 2 Dense layers of 64 units each to the model. Let `relu` be the activation function.\n",
    "# Note: Specify the input_shape argument for the first layer.\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a final Dense layer that classifies the output\n",
    "# Note: You should use 46 units since out output dimension is going to be the number of output classes). \n",
    "# Let `softmax` be the activation function.\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to note about this architecture:\n",
    "\n",
    "* We are ending the network with a `Dense` layer of size 46. This means that for each input sample, our network will output a \n",
    "46-dimensional vector. Each entry in this vector (each dimension) will encode a different output class.\n",
    "* We are using the Relu function for activation.\n",
    "* The last layer uses a `softmax` activation. It means that the network will \n",
    "output a _probability distribution_ over the 46 different output classes, i.e. for every input sample, the network will produce a \n",
    "46-dimensional output vector where `output[i]` is the probability that the sample belongs to class `i`. The 46 scores will sum to 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model is \"freezing\" the model with certain attributes set such as `loss`, `optimizer`, `metrics` etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model with a \"rmsprop\" optimizer, \"categorical_crossentropy\" loss and \"accuracy\" \\\n",
    "# metric.\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras you can specify the different parameters above as strings such as \"rmsprop\" or as keras.optimizers.RMSprop. You can do the same for loss and metrics. Here are a list of [optimizers](https://keras.io/optimizers/), [loss functions](https://keras.io/losses/) and [metrics](https://keras.io/metrics/) that are available in Keras. \n",
    "\n",
    "In our example above the best loss function to use `categorical_crossentropy` since it measures the distance between \n",
    "the probability distribution output by our network and the true distribution of the labels. By minimizing the \n",
    "distance between these two distributions, we train our network to output something as close as possible to the true labels.\n",
    "\n",
    "Another point to note is if we had used output labels as integer tensors instead of one-hot encoded vectors, then we should use`sparse_categorical_crossentropy` instead of `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model\n",
    "\n",
    "Let's set apart 1,000 samples in our training data to use as a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the training data into train and validation datasets.\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's train our network for 20 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.0741 - acc: 0.9578 - val_loss: 1.4263 - val_acc: 0.7840\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.0726 - acc: 0.9603 - val_loss: 1.4378 - val_acc: 0.7820\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.0737 - acc: 0.9578 - val_loss: 1.4624 - val_acc: 0.7770\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.0716 - acc: 0.9583 - val_loss: 1.4730 - val_acc: 0.7750\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0714 - acc: 0.9609 - val_loss: 1.5280 - val_acc: 0.7770\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0712 - acc: 0.9597 - val_loss: 1.5399 - val_acc: 0.7660\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0721 - acc: 0.9583 - val_loss: 1.4768 - val_acc: 0.7790\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0704 - acc: 0.9595 - val_loss: 1.5058 - val_acc: 0.7730\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.0713 - acc: 0.9569 - val_loss: 1.5016 - val_acc: 0.7710\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0701 - acc: 0.9585 - val_loss: 1.5451 - val_acc: 0.7750\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.0692 - acc: 0.9597 - val_loss: 1.5262 - val_acc: 0.7700\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0716 - acc: 0.9570 - val_loss: 1.5092 - val_acc: 0.7720\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 94us/step - loss: 0.0700 - acc: 0.9588 - val_loss: 1.5616 - val_acc: 0.7670\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0695 - acc: 0.9588 - val_loss: 1.5022 - val_acc: 0.7790\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.0701 - acc: 0.9577 - val_loss: 1.5500 - val_acc: 0.7740\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 94us/step - loss: 0.0674 - acc: 0.9594 - val_loss: 1.5290 - val_acc: 0.7750\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.0694 - acc: 0.9568 - val_loss: 1.6084 - val_acc: 0.7710\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0686 - acc: 0.9578 - val_loss: 1.5922 - val_acc: 0.7700\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.0679 - acc: 0.9605 - val_loss: 1.5414 - val_acc: 0.7770\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.0684 - acc: 0.9580 - val_loss: 1.6161 - val_acc: 0.7610\n"
     ]
    }
   ],
   "source": [
    "# Use the `fit` call with the above training and validation datasets. \n",
    "# Use can use a batch size of 512.\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display its loss and accuracy curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIjElBRERif0/3roUfRDJrZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26b87113c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhLL/wd0LxB3tkuTlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26b86a32b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the network starts overfitting after 8 epochs. \n",
    "\n",
    "## Let's train a new network from scratch for 8 epochs, then let's evaluate it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/8\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 2.6295 - acc: 0.5199 - val_loss: 1.7297 - val_acc: 0.6520\n",
      "Epoch 2/8\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 1.4180 - acc: 0.7010 - val_loss: 1.2797 - val_acc: 0.7160\n",
      "Epoch 3/8\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 1.0405 - acc: 0.7759 - val_loss: 1.1327 - val_acc: 0.7480\n",
      "Epoch 4/8\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.8151 - acc: 0.8282 - val_loss: 1.0313 - val_acc: 0.7740\n",
      "Epoch 5/8\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.6458 - acc: 0.8633 - val_loss: 0.9390 - val_acc: 0.8010\n",
      "Epoch 6/8\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.5122 - acc: 0.8924 - val_loss: 0.9040 - val_acc: 0.8170\n",
      "Epoch 7/8\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.4116 - acc: 0.9131 - val_loss: 0.8878 - val_acc: 0.8110\n",
      "Epoch 8/8\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.3319 - acc: 0.9285 - val_loss: 0.8971 - val_acc: 0.8140\n"
     ]
    }
   ],
   "source": [
    "# Use the same model from before and train the model as before. \n",
    "# However for this run let the number of epochs be 8.\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=8,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 116us/step\n"
     ]
    }
   ],
   "source": [
    "# Use `evaluate` the model with the test training input(x_test) and \n",
    "# the one-hot encoded labels(one_hot_test_labels).\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our approach reaches an accuracy of ~78%. With a balanced binary classification problem, the accuracy reached by a purely random classifier \n",
    "would be 50%, but in our case it is closer to 19%, so our results seem pretty good, at least when compared to a random baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1861086375779163"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Now let us try with a larger network with 128 Dense units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 2.1474 - acc: 0.5600 - val_loss: 1.3717 - val_acc: 0.6890\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 129us/step - loss: 1.1111 - acc: 0.7544 - val_loss: 1.0968 - val_acc: 0.7730\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.7735 - acc: 0.8317 - val_loss: 1.0010 - val_acc: 0.7890\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.5702 - acc: 0.8757 - val_loss: 0.9006 - val_acc: 0.8170\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 0.4114 - acc: 0.9132 - val_loss: 0.8740 - val_acc: 0.8200\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 130us/step - loss: 0.3162 - acc: 0.9323 - val_loss: 0.9074 - val_acc: 0.8030\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.2459 - acc: 0.9434 - val_loss: 0.8669 - val_acc: 0.8170\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.2086 - acc: 0.9474 - val_loss: 0.9190 - val_acc: 0.8050\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 146us/step - loss: 0.1765 - acc: 0.9506 - val_loss: 0.9065 - val_acc: 0.8150\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 165us/step - loss: 0.1596 - acc: 0.9540 - val_loss: 0.9728 - val_acc: 0.7980\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 2s 192us/step - loss: 0.1508 - acc: 0.9535 - val_loss: 0.9336 - val_acc: 0.8160\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 2s 192us/step - loss: 0.1335 - acc: 0.9541 - val_loss: 0.9896 - val_acc: 0.8060\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 169us/step - loss: 0.1246 - acc: 0.9570 - val_loss: 1.0679 - val_acc: 0.7930\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 0.1249 - acc: 0.9574 - val_loss: 1.0045 - val_acc: 0.8090\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 0.1220 - acc: 0.9550 - val_loss: 1.0490 - val_acc: 0.7950\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 185us/step - loss: 0.1146 - acc: 0.9583 - val_loss: 1.0706 - val_acc: 0.8050\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 2s 192us/step - loss: 0.1124 - acc: 0.9575 - val_loss: 1.0679 - val_acc: 0.7990\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 2s 190us/step - loss: 0.1101 - acc: 0.9562 - val_loss: 1.0518 - val_acc: 0.8000\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 0.1098 - acc: 0.9569 - val_loss: 1.0096 - val_acc: 0.8130\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 163us/step - loss: 0.1033 - acc: 0.9574 - val_loss: 1.0757 - val_acc: 0.8020\n",
      "2246/2246 [==============================] - 0s 212us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26f12f01d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the same model as before but with 128 units set for the first two Dense layers. `compile`, `fit` and `evaluate`\n",
    "# the model as before. You can also plot the loss and accuracy to see the behavior of the model.\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Define your model here\n",
    "# ...\n",
    "# Exercise 1: Solution\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, with the larger network we get a slight increase in accuracy but the network seems to perform just as good previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Now let us train the model with a single Dense layer network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 3.7771 - acc: 0.0749 - val_loss: 3.7295 - val_acc: 0.0780\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 3.6916 - acc: 0.0687 - val_loss: 3.6520 - val_acc: 0.0760\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 3.6090 - acc: 0.0707 - val_loss: 3.5692 - val_acc: 0.0610\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 3.5197 - acc: 0.0618 - val_loss: 3.4786 - val_acc: 0.0600\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 3.4241 - acc: 0.0618 - val_loss: 3.3826 - val_acc: 0.0600\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 3.3232 - acc: 0.0626 - val_loss: 3.2813 - val_acc: 0.0610\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 3.2185 - acc: 0.0970 - val_loss: 3.1760 - val_acc: 0.3200\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 3.1099 - acc: 0.3482 - val_loss: 3.0674 - val_acc: 0.3540\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 2.9995 - acc: 0.3518 - val_loss: 2.9584 - val_acc: 0.3540\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 2.8917 - acc: 0.3518 - val_loss: 2.8534 - val_acc: 0.3540\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 2.7887 - acc: 0.3519 - val_loss: 2.7538 - val_acc: 0.3540\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 2.6944 - acc: 0.3520 - val_loss: 2.6648 - val_acc: 0.3540\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 2.6099 - acc: 0.3522 - val_loss: 2.5851 - val_acc: 0.3550\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 2.5354 - acc: 0.3523 - val_loss: 2.5159 - val_acc: 0.3550\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 2.4702 - acc: 0.3523 - val_loss: 2.4545 - val_acc: 0.3550\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 2.4127 - acc: 0.3528 - val_loss: 2.4017 - val_acc: 0.3550\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 2.3626 - acc: 0.3528 - val_loss: 2.3546 - val_acc: 0.3560\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 2.3170 - acc: 0.3528 - val_loss: 2.3129 - val_acc: 0.3560\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 2.2751 - acc: 0.3527 - val_loss: 2.2732 - val_acc: 0.3550\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 104us/step - loss: 2.2363 - acc: 0.3528 - val_loss: 2.2363 - val_acc: 0.3550\n",
      "2246/2246 [==============================] - 0s 61us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkoWIiKSlZCEiImn9f06n4T6gTklPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f264a079ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the same model as before but with 1 units set for a single Dense layer. `compile`, `fit` and `evaluate`\n",
    "# the model as before. You can also plot the loss and accuracy to see the behavior of the model.\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Define your model here\n",
    "# ...\n",
    "# Exercise 2: Solution\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "\n",
    "plt.clf()   # clear figure\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the accuracy stagnates at around 35% since the network is unable to learn any new information from\n",
    "the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating predictions on new data\n",
    "\n",
    "We can verify that the `predict` method of our model instance returns a probability distribution over all 46 topics. Let's generate topic \n",
    "predictions for all of the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in `predictions` is a vector of length 46:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients in this vector sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest entry is the predicted class, i.e. the class with the highest probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with overfitting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common ways to deal with overfitting is to train the model on more data or even to reduce the capacity of the network.\n",
    "A bigger network gets its training loss near zero very quickly. The more capacity the network has, the quicker it will be able to model the training data (resulting in a low training loss), but the more susceptible it is to overfitting (resulting in a large difference between the training and validation loss). Other techniques to deal with overfitting is using weight regularization and dropout. Keras provides APIs that make it very simple to use these techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding weight regularization:\n",
    "A common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights to only take small values, which makes the distribution of weight values more \"regular\". This is called \"weight regularization\", and it is done by adding to the loss function of the network a cost associated with having large weights. This cost comes in two flavors:\n",
    "\n",
    "L1 regularization, where the cost added is proportional to the absolute value of the weights coefficients (i.e. to what is called the \"L1 norm\" of the weights).\n",
    "L2 regularization, where the cost added is proportional to the square of the value of the weights coefficients (i.e. to what is called the \"L2 norm\" of the weights). L2 regularization is also called weight decay in the context of neural networks. Don't let the different name confuse you: weight decay is mathematically the exact same as L2 regularization.\n",
    "In Keras, [weight regularization](https://keras.io/regularizers/) is added by passing weight regularizer instances to layers as keyword arguments. Let's add L2 weight regularization to an example Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regularizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e0b6c56123c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmock_dense_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'regularizers' is not defined"
     ]
    }
   ],
   "source": [
    "mock_dense_layer = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu', input_shape=(10000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dropout:\n",
    "[Dropout](https://keras.io/layers/core/), applied to a layer, consists of randomly \"dropping out\" (i.e. setting to zero) a number of output features of the layer during training. Let's say a given layer would normally have returned a vector [0.2, 0.5, 1.3, 0.8, 1.1] for a given input sample during training; after applying dropout, this vector will have a few zero entries distributed at random, e.g. [0, 0.5, 1.3, 0, 1.1]. The \"dropout rate\" is the fraction of the features that are being zeroed-out; it is usually set between 0.2 and 0.5. At test time, no units are dropped out, and instead the layer's output values are scaled down by a factor equal to the dropout rate, so as to balance for the fact that more units are active than at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mock_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-72f5dcde8180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# An example Dropout layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmock_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmock_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0.5 is the dropout rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mock_model' is not defined"
     ]
    }
   ],
   "source": [
    "# An example Dropout layer:\n",
    "#...\n",
    "mock_model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "mock_model.add(layers.Dropout(0.5)) # 0.5 is the dropout rate\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "You can use Keras built-in [callbacks](https://keras.io/callbacks/) to checkpoint your model, save TensorBoard summaries, adjust learning rate during training etc.\n",
    "Callbacks are a way to perform an action, view internal state or model statistics at the beginning/end of the training loop, an epoch or a step in the fit loop.\n",
    "Let's instantiate the ModelCheckpoint and TensorBoard callback:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Create a ModelCheckpoint and TensorBoard callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.core.computation' has no attribute 'expressions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-731d199802f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                period=1)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtensorboard_cb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/var/logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Let us use our model from above:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, histogram_freq, batch_size, write_graph, write_grads, write_images, embeddings_freq, embeddings_layer_names, embeddings_metadata)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprojector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You need the TensorFlow module installed to use TensorBoard.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfactorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distributions/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftplus_inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtridiag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf_normal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_compute_weighted_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_RegressionHead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlearn_io\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProblemType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNEstimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDNNRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetric_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdnn_linear_combined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhead_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetric_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhead_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_feeder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaved_model_export_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_dask_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_dask_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdask_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHAS_DASK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0mallowed_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mHAS_DASK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dask/dataframe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from .core import (DataFrame, Series, Index, _Frame, map_partitions,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    repartition, to_delayed, to_datetime, to_timedelta)\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mPANDAS_VERSION\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m'0.20.0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_numexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas.core.computation' has no attribute 'expressions'"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "# Create a ModelCheckpoint callback by specifying a filepath such a s'/tmp/checkpoints'. You can look at some of the\n",
    "# other parameters that you can set in the link above.\n",
    "# ...\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "# model_checkpoint_cb = \n",
    "\n",
    "# Create a TensorBoard callback that writes model summaries to a given directory such as '/tmp/logs'.\n",
    "# tensorboard_cb = \n",
    "\n",
    "model_checkpoint_cb = callbacks.ModelCheckpoint('/tmp/checkpoints',\n",
    "                                               monitor='val_loss',\n",
    "                                               period=1)\n",
    "\n",
    "tensorboard_cb = callbacks.TensorBoard(log_dir='/var/logs')\n",
    "\n",
    "# Let us use our model from above:\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Pass the callbacks instantiated above to the `callbacks` parameter in the `fit` call.\n",
    "history = model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=512,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to view TensorBoard summaries by using the following command:\n",
    "`tensorboard --logdir=/full_path_to_your_logs`. Make sure to have installed the TensorBoard pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 1: Solution\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 2: Solution\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(1, activation='relu', input_shape=(10000,)))\n",
    "# model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 3: Solution\n",
    "# model_checkpoint_cb = callbacks.ModelCheckpoint('/tmp/checkpoints',\n",
    "#                                                monitor='val_loss',\n",
    "#                                                period=1)\n",
    "\n",
    "# tensorboard_cb = callbacks.TensorBoard(log_dir='/tmp/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
