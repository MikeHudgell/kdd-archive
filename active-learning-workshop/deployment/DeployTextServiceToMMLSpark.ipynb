{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deploying a scikit pipeline onto MML Spark\n",
    "This notebook shows how to take your scikit pipeline and make a web service out of it using MML Spark Serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files here\n"
     ]
    }
   ],
   "source": [
    "# get the text data from the github repo and unzip it\n",
    "from fit_and_store_pipeline import unzip_file_here\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "if not os.path.isfile('./text_data/attack_data.csv'):\n",
    "    if not os.path.isfile('./text_data.zip'): \n",
    "        urllib.request.urlretrieve('https://activelearning.blob.core.windows.net/activelearningdemo/text_data.zip', 'text_data.zip')\n",
    "    unzip_file_here('text_data.zip')\n",
    "\n",
    "if not os.path.isfile('miniglove_6B_50d_w2v.txt'):\n",
    "    unzip_file_here('miniglove_6B_50d_w2v.zip')\n",
    "    \n",
    "print('Data files here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing it the scikit way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install all the required dependencies\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import random\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from fit_and_store_pipeline import *\n",
    "\n",
    "# text preprocessor\n",
    "preprocessor = GensimPreprocessor()\n",
    "\n",
    "# word2vec featurizer\n",
    "w2v_file = 'miniglove_6B_50d_w2v.txt' # convert glove file to w2v format using gensim.scripts.glove2word2vec\n",
    "word_vectors = KeyedVectors.load_word2vec_format(w2v_file, binary=False)\n",
    "vectorizer = AvgWordVectorFeaturizer(word_vectors)\n",
    "\n",
    "# classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=1)\n",
    "\n",
    "# assemble a scikit-learn pipeline\n",
    "model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', classifier),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a train-test data pair\n",
    "\n",
    "from fit_and_store_pipeline import create_train_test_split\n",
    "\n",
    "# requires training_set_01.csv and test_set_01.csv to be present\n",
    "training_data, test_data = create_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessor', GensimPreprocessor(newline_token=None)), ('vectorizer', <fit_and_store_pipeline.AvgWordVectorFeaturizer object at 0x7f0ffe92ff28>), ('classifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_...estimators=100, n_jobs=1,\n",
       "            oob_score=True, random_state=1, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test - does the pipeline fit happily in a scikit fashion?\n",
    "fitted_pipe = model_pipeline.fit(training_data.comment, [int(x) for x in training_data.is_attack])\n",
    "fitted_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction from the scikit pipeline\n",
    "test_attacks = ['You are scum.', 'I like your shoes.', 'You are pxzx.', \n",
    "             'Your mother was a hamster and your father smelt of elderberries',\n",
    "             'One bag of hagfish slime, please']\n",
    "\n",
    "fitted_pipe.predict(test_attacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could now deploy the native scikit pipeline using Azure ML Services. But today, we want to show the open-source way - MMLSpark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model as a Spark Streaming job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[comment: string, year: bigint, logged_in: boolean, ns: string, sample: string, split: string, count: bigint, avg_attack: double, is_attack: boolean]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn the training data from a pandas.DataFrame into a spark.DataFrame\n",
    "train_sdf = spark.createDataFrame(training_data)\n",
    "train_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     comment  year  logged_in  \\\n",
      "rev_id                                                                          \n",
      "416170166  NEWLINE_TOKENNEWLINE_TOKEN== Please stop? ==NE...  2011      False   \n",
      "180046743  NEWLINE_TOKENfine I get threatened and he is a...  2007       True   \n",
      "536943251  Lets see double standard of some one who tries...  2013       True   \n",
      "93070973   my comments in on the arbitration request he f...  2006       True   \n",
      "272666818  `NEWLINE_TOKENNEWLINE_TOKEN==You maybe interes...  2009       True   \n",
      "\n",
      "                ns   sample  split  count  avg_attack  is_attack  \n",
      "rev_id                                                            \n",
      "416170166     user  blocked  train      8    0.125000      False  \n",
      "180046743     user  blocked  train      9    0.222222      False  \n",
      "536943251  article  blocked    dev     10    0.200000      False  \n",
      "93070973      user  blocked   test      9    0.000000      False  \n",
      "272666818     user   random  train     10    0.000000      False  \n",
      "         F0        F1        F2        F3        F4        F5        F6  \\\n",
      "0 -0.182730  0.314910  0.578810 -0.451117  0.138780 -0.619488 -0.023427   \n",
      "1  0.097344  0.116066 -0.129499 -0.183653  0.444738  0.039917 -0.334430   \n",
      "2  0.349084  0.100745 -0.045672 -0.082555  0.361282  0.197562 -0.288936   \n",
      "3  0.147019  0.124288 -0.327029 -0.114524  0.330564  0.050204 -0.517314   \n",
      "4  0.308448  0.147917  0.065566 -0.116795  0.349226  0.003178 -0.419646   \n",
      "\n",
      "         F7        F8        F9    ...           F41       F42       F43  \\\n",
      "0  0.537403  0.039993 -0.349530    ...      0.191119  0.263763  0.151110   \n",
      "1  0.123569 -0.113374  0.226857    ...      0.003958  0.023422  0.221236   \n",
      "2 -0.192525 -0.094679  0.063190    ...      0.079737  0.052697  0.193157   \n",
      "3  0.237108 -0.212837 -0.163897    ...      0.156871 -0.208901  0.238045   \n",
      "4 -0.121481 -0.071388 -0.198658    ...     -0.170733  0.106964  0.088627   \n",
      "\n",
      "        F44       F45       F46       F47       F48       F49  is_attack  \n",
      "0  0.493073  0.359977  0.113137  0.025230  0.238686  0.728423          0  \n",
      "1 -0.099966 -0.097279 -0.299032 -0.088193  0.067070  0.082129          0  \n",
      "2  0.031384  0.035903 -0.199008  0.127317  0.035283 -0.024386          0  \n",
      "3 -0.185906  0.023333 -0.140447  0.142880 -0.089312 -0.255789          0  \n",
      "4  0.036544  0.094055 -0.127313  0.134295 -0.051470  0.079612          0  \n",
      "\n",
      "[5 rows x 51 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[F0: double, F1: double, F2: double, F3: double, F4: double, F5: double, F6: double, F7: double, F8: double, F9: double, F10: double, F11: double, F12: double, F13: double, F14: double, F15: double, F16: double, F17: double, F18: double, F19: double, F20: double, F21: double, F22: double, F23: double, F24: double, F25: double, F26: double, F27: double, F28: double, F29: double, F30: double, F31: double, F32: double, F33: double, F34: double, F35: double, F36: double, F37: double, F38: double, F39: double, F40: double, F41: double, F42: double, F43: double, F44: double, F45: double, F46: double, F47: double, F48: double, F49: double, is_attack: bigint]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforms - only pipeline\n",
    "trans_pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('vectorizer', vectorizer)\n",
    "    ])\n",
    "\n",
    "trans_pipe.fit(training_data.comment, [int(x) for x in training_data.is_attack])\n",
    "featurized_train = trans_pipe.transform(training_data.comment)\n",
    "feature_names = [ 'F' + str(i) for i in range(featurized_train.shape[1]) ]\n",
    "\n",
    "ft_df = pd.DataFrame(featurized_train, columns=feature_names);\n",
    "ft_df['is_attack'] = [1 if x else 0 for x in training_data['is_attack']]\n",
    "\n",
    "print(training_data.head())\n",
    "print(ft_df.head())\n",
    "\n",
    "featurized_train_sdf = spark.createDataFrame(ft_df)\n",
    "featurized_train_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mmlspark import TrainClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "model = TrainClassifier(model=RandomForestClassifier(), \n",
    "                        labelCol=\"is_attack\", \n",
    "                        numFeatures=256).fit(featurized_train_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the model\n",
    "\n",
    "# first, featurize the test data using the same pipeline\n",
    "featurized_test = trans_pipe.transform(test_data.comment)\n",
    "# use the same feature names we've had\n",
    "# feature_names = [ 'F' + str(i) for i in range(featurized_test.shape[1]) ]\n",
    "\n",
    "ftst_df = pd.DataFrame(featurized_test, columns=feature_names);\n",
    "ftst_df['is_attack'] = [1 if x else 0 for x in test_data['is_attack']]\n",
    "\n",
    "# second, make a prediction on the test set\n",
    "ftst_sdf = spark.createDataFrame(ft_df)\n",
    "\n",
    "prediction = model.transform(ftst_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>DenseMatrix([[ 276.,    6.],\\n             [  ...</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.98218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation_type                                   confusion_matrix  \\\n",
       "0  Classification  DenseMatrix([[ 276.,    6.],\\n             [  ...   \n",
       "\n",
       "   accuracy  precision    recall      AUC  \n",
       "0  0.922727   0.955882  0.822785  0.98218  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# third, compute performance stats\n",
    "from mmlspark import ComputeModelStatistics, TrainedClassifierModel\n",
    "metrics = ComputeModelStatistics().transform(prediction)\n",
    "metrics.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now deploy the trained classifier as a streaming job\n",
    "# define the interface to be like the model's input\n",
    "\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import *\n",
    "import uuid\n",
    "\n",
    "serving_inputs = spark.readStream.server() \\\n",
    "    .address(\"localhost\", 9999, \"text_api\") \\\n",
    "    .load()\\\n",
    "    .withColumn(\"variables\", from_json(col(\"value\"), ftst_sdf.schema))\\\n",
    "    .select(\"id\",\"variables.*\")\n",
    "\n",
    "# says to extract \"variables\" from the \"value\" field of json-encoded webservice input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serving_outputs = model.transform(serving_inputs) \\\n",
    "  .withColumn(\"scored_labels\", col(\"scored_labels\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = serving_outputs.writeStream \\\n",
    "    .server() \\\n",
    "    .option(\"name\", \"text_api\") \\\n",
    "    .queryName(\"my_query\") \\\n",
    "    .option(\"replyCol\", \"scored_labels\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoints-{}\".format(uuid.uuid1())) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if we want to change something above, we'll need\n",
    "# to stop the active server\n",
    "\n",
    "server.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(trans_pipe.transform(test_attacks), columns=feature_names)\n",
    "\n",
    "# float32s are not json-serializable, float64s are\n",
    "data = data.applymap(lambda x: np.float64(x) if isinstance(x, numbers.Number) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, F0: double, F1: double, F2: double, F3: double, F4: double, F5: double, F6: double, F7: double, F8: double, F9: double, F10: double, F11: double, F12: double, F13: double, F14: double, F15: double, F16: double, F17: double, F18: double, F19: double, F20: double, F21: double, F22: double, F23: double, F24: double, F25: double, F26: double, F27: double, F28: double, F29: double, F30: double, F31: double, F32: double, F33: double, F34: double, F35: double, F36: double, F37: double, F38: double, F39: double, F40: double, F41: double, F42: double, F43: double, F44: double, F45: double, F46: double, F47: double, F48: double, F49: double, is_attack: bigint]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs and outputs - schema\n",
    "serving_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, F0: double, F1: double, F2: double, F3: double, F4: double, F5: double, F6: double, F7: double, F8: double, F9: double, F10: double, F11: double, F12: double, F13: double, F14: double, F15: double, F16: double, F17: double, F18: double, F19: double, F20: double, F21: double, F22: double, F23: double, F24: double, F25: double, F26: double, F27: double, F28: double, F29: double, F30: double, F31: double, F32: double, F33: double, F34: double, F35: double, F36: double, F37: double, F38: double, F39: double, F40: double, F41: double, F42: double, F43: double, F44: double, F45: double, F46: double, F47: double, F48: double, F49: double, is_attack: bigint, scores: vector, scored_probabilities: vector, scored_labels: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to : 'You are scum.' is 1.0\n",
      "Response to : 'I like your shoes.' is 0.0\n",
      "Response to : 'You are pxzx.' is 0.0\n",
      "Response to : 'Your mother was a hamster and your father smelt of elderberries' is 1.0\n",
      "Response to : 'One bag of hagfish slime, please' is 1.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# calling the service\n",
    "\n",
    "for instance in range(len(test_attacks)):    \n",
    "    row_as_dict = data.to_dict('records')[instance]        \n",
    "    r = requests.post(data=json.dumps(row_as_dict), url=\"http://localhost:9999/text_api\")\n",
    "    time.sleep(0.5)\n",
    "    print(\"Response to : '{}' is {}\".format(test_attacks[instance], r.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
