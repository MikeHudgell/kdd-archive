{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text classification on Spark with MMLSpark\n",
    "\n",
    "This notebook shows how to make a text classfication web service using MML Spark serving and deploy it to a Sparl cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files here\n"
     ]
    }
   ],
   "source": [
    "# get the text data from the github repo and unzip it\n",
    "from fit_and_store_pipeline import unzip_file_here\n",
    "import urllib\n",
    "import os\n",
    "\n",
    "if not os.path.isfile('./text_data/attack_data.csv'):\n",
    "    if not os.path.isfile('./text_data.zip'): \n",
    "        urllib.request.urlretrieve('https://activelearning.blob.core.windows.net/activelearningdemo/text_data.zip', 'text_data.zip')\n",
    "    unzip_file_here('text_data.zip')\n",
    "\n",
    "if not os.path.isfile('miniglove_6B_50d_w2v.txt'):\n",
    "    unzip_file_here('miniglove_6B_50d_w2v.zip')\n",
    "    \n",
    "print('Data files here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure workers spawned use the same environment/executable\n",
    "import os\n",
    "import sys \n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a train-test data pair\n",
    "\n",
    "from fit_and_store_pipeline import create_train_test_split\n",
    "\n",
    "# requires training_set_01.csv and test_set_01.csv to be present\n",
    "training_data, test_data = create_train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.4:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MyApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8b4d9ed7b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if pyspark is missing on your machine, you could do\n",
    "# !{sys.executable} -m pip install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# configure Spark session to use mmlspark v0.13 (DSVM comes with 0.12)\n",
    "sparkSB = SparkSession.builder.appName(\"MyApp\")\\\n",
    "        .config(\"spark.jars.packages\", \"Azure:mmlspark:0.13\")\\\n",
    "        .config(\"spark.pyspark.python\", sys.executable)\\\n",
    "        .config(\"spark.pyspark.driver.python\", sys.executable)\n",
    "\n",
    "spark = sparkSB.getOrCreate()\n",
    "\n",
    "import mmlspark\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data in the spark format\n",
    "\n",
    "train_sdf = spark.createDataFrame(training_data)\n",
    "train_sdf = train_sdf\\\n",
    "            .withColumn(\"label\", train_sdf[\"is_attack\"].cast('integer'))\\\n",
    "            .select([\"comment\", \"label\"])\n",
    "                                                             \n",
    "test_sdf = spark.createDataFrame(test_data)\n",
    "test_sdf = test_sdf\\\n",
    "            .withColumn(\"label\", test_sdf[\"is_attack\"].cast('integer'))\\\n",
    "            .select([\"comment\", \"label\"])\n",
    "\n",
    "# What have we?\n",
    "# train_sdf.limit(10).toPandas()\n",
    "# train_sdf.groupBy(\"label\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ML-Lib pipeline involving preprocessor and vectorizer\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# comment is the text field\n",
    "tokenizer = Tokenizer(inputCol=\"comment\", outputCol=\"words\")\n",
    "partitions = train_sdf.rdd.getNumPartitions()\n",
    "word2vec = Word2Vec(maxIter=4, seed=44, inputCol=\"words\", outputCol=\"features\"\n",
    "                    # , numPartitions=partitions\n",
    "                    )\n",
    "rfc = RandomForestClassifier(labelCol=\"label\")\n",
    "textClassifier = Pipeline(stages = [tokenizer, word2vec, rfc]).fit(train_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.023442650213837624, 0.02603577682748437, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.02291071817411908, 0.0390844551979431, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.030262907435436075, 0.04049098381727207, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.053226795885711914, 0.04567255172878504, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.03638704048875624, 0.04077244628793918, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           features\n",
       "0      0  [-0.023442650213837624, 0.02603577682748437, -...\n",
       "1      0  [-0.02291071817411908, 0.0390844551979431, -0....\n",
       "2      0  [-0.030262907435436075, 0.04049098381727207, -...\n",
       "3      0  [-0.053226795885711914, 0.04567255172878504, -...\n",
       "4      0  [-0.03638704048875624, 0.04077244628793918, -0..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you are going to try a couple different models, pre-featurize first\n",
    "textFeaturizer = Pipeline(stages = [tokenizer, word2vec]).fit(train_sdf)\n",
    "ptrain = textFeaturizer.transform(train_sdf).select([\"label\", \"features\"])\n",
    "ptest = textFeaturizer.transform(test_sdf).select([\"label\", \"features\"])\n",
    "ptrain.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>words</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are scum.</td>\n",
       "      <td>[you, are, scum.]</td>\n",
       "      <td>[-0.028500227102388937, 0.07817639410495758, 0...</td>\n",
       "      <td>[9.263528611802501, 10.736471388197497]</td>\n",
       "      <td>[0.46317643059012503, 0.5368235694098749]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I like your shoes.</td>\n",
       "      <td>[i, like, your, shoes.]</td>\n",
       "      <td>[-0.029791212640702724, 0.07729054428637028, 0...</td>\n",
       "      <td>[12.289011431327564, 7.710988568672435]</td>\n",
       "      <td>[0.6144505715663782, 0.3855494284336217]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are pxzx.</td>\n",
       "      <td>[you, are, pxzx.]</td>\n",
       "      <td>[-0.028500227102388937, 0.07817639410495758, 0...</td>\n",
       "      <td>[9.263528611802501, 10.736471388197497]</td>\n",
       "      <td>[0.46317643059012503, 0.5368235694098749]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your mother was a hamster and your father smel...</td>\n",
       "      <td>[your, mother, was, a, hamster, and, your, fat...</td>\n",
       "      <td>[-0.031833043110302904, 0.05804957855831493, -...</td>\n",
       "      <td>[10.379377440137818, 9.620622559862184]</td>\n",
       "      <td>[0.5189688720068909, 0.4810311279931092]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One bag of hagfish slime, please</td>\n",
       "      <td>[one, bag, of, hagfish, slime,, please]</td>\n",
       "      <td>[-0.028880382111916937, 0.04981327926119168, -...</td>\n",
       "      <td>[11.372786956168316, 8.627213043831686]</td>\n",
       "      <td>[0.5686393478084157, 0.4313606521915843]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  \\\n",
       "0                                      You are scum.   \n",
       "1                                 I like your shoes.   \n",
       "2                                      You are pxzx.   \n",
       "3  Your mother was a hamster and your father smel...   \n",
       "4                   One bag of hagfish slime, please   \n",
       "\n",
       "                                               words  \\\n",
       "0                                  [you, are, scum.]   \n",
       "1                            [i, like, your, shoes.]   \n",
       "2                                  [you, are, pxzx.]   \n",
       "3  [your, mother, was, a, hamster, and, your, fat...   \n",
       "4            [one, bag, of, hagfish, slime,, please]   \n",
       "\n",
       "                                            features  \\\n",
       "0  [-0.028500227102388937, 0.07817639410495758, 0...   \n",
       "1  [-0.029791212640702724, 0.07729054428637028, 0...   \n",
       "2  [-0.028500227102388937, 0.07817639410495758, 0...   \n",
       "3  [-0.031833043110302904, 0.05804957855831493, -...   \n",
       "4  [-0.028880382111916937, 0.04981327926119168, -...   \n",
       "\n",
       "                             rawPrediction  \\\n",
       "0  [9.263528611802501, 10.736471388197497]   \n",
       "1  [12.289011431327564, 7.710988568672435]   \n",
       "2  [9.263528611802501, 10.736471388197497]   \n",
       "3  [10.379377440137818, 9.620622559862184]   \n",
       "4  [11.372786956168316, 8.627213043831686]   \n",
       "\n",
       "                                 probability  prediction  \n",
       "0  [0.46317643059012503, 0.5368235694098749]         1.0  \n",
       "1   [0.6144505715663782, 0.3855494284336217]         0.0  \n",
       "2  [0.46317643059012503, 0.5368235694098749]         1.0  \n",
       "3   [0.5189688720068909, 0.4810311279931092]         0.0  \n",
       "4   [0.5686393478084157, 0.4313606521915843]         0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction on some new data\n",
    "import pandas as pd\n",
    "\n",
    "test_attacks = ['You are scum.', 'I like your shoes.', 'You are pxzx.', \n",
    "             'Your mother was a hamster and your father smelt of elderberries',\n",
    "             'One bag of hagfish slime, please']\n",
    "\n",
    "ta_sdf = spark.createDataFrame(pd.DataFrame({\"comment\" : test_attacks}))\n",
    "\n",
    "prediction = textClassifier.transform(ta_sdf)\n",
    "prediction.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>798</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count    \n",
       "prediction   0.0 1.0\n",
       "label               \n",
       "0            798  60\n",
       "1            110  32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prediction on the larger test set\n",
    "\n",
    "scored_test = textClassifier.transform(test_sdf)\n",
    "scored_test.groupBy([\"label\", \"prediction\"]).count()\\\n",
    "            .toPandas().pivot(index=\"label\", columns=\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model as a Spark Streaming job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now deploy the trained classifier as a streaming job\n",
    "# define the interface to be like the model's input\n",
    "\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import *\n",
    "import uuid\n",
    "\n",
    "serving_inputs = spark.readStream.server() \\\n",
    "    .address(\"localhost\", 9977, \"text_api\") \\\n",
    "    .load()\\\n",
    "    .withColumn(\"variables\", from_json(col(\"value\"), test_sdf.schema))\\\n",
    "    .select(\"id\",\"variables.*\")\n",
    "\n",
    "# says to extract \"variables\" from the \"value\" field of json-encoded webservice input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_outputs = textClassifier.transform(serving_inputs) \\\n",
    "  .withColumn(\"prediction\", col(\"prediction\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = serving_outputs.writeStream \\\n",
    "    .server() \\\n",
    "    .option(\"name\", \"text_api\") \\\n",
    "    .queryName(\"mml_text_query\") \\\n",
    "    .option(\"replyCol\", \"prediction\") \\\n",
    "    .option(\"checkpointLocation\", \"checkpoints-{}\".format(uuid.uuid1())) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to change something above (like the port), we'll need\n",
    "# to stop the active server\n",
    "\n",
    "server.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, comment: string, label: int]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs and outputs - schema\n",
    "serving_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, comment: string, label: int, words: array<string>, features: vector, rawPrediction: vector, probability: vector, prediction: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response to : 'You are scum.' is 1.0\n",
      "Response to : 'I like your shoes.' is 0.0\n",
      "Response to : 'You are pxzx.' is 1.0\n",
      "Response to : 'Your mother was a hamster and your father smelt of elderberries' is 0.0\n",
      "Response to : 'One bag of hagfish slime, please' is 0.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# calling the service\n",
    "data = pd.DataFrame({ \"comment\" : test_attacks })\n",
    "\n",
    "for instance in range(len(test_attacks)):    \n",
    "    row_as_dict = data.to_dict('records')[instance]        \n",
    "    r = requests.post(data=json.dumps(row_as_dict), url=\"http://localhost:9977/text_api\")\n",
    "    time.sleep(0.2)\n",
    "    print(\"Response to : '{}' is {}\".format(test_attacks[instance], r.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
