{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformer based Machine Translation Using GluonNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In this notebook, we introduce the *Transformer* model for sequence to sequence transduction.\n",
    "Introduced in the [2017 NIPS paper \"Attention is All You Need](https://arxiv.org/abs/1706.03762), the models are both more accurate and lighter to train than previous seq2seq models.\n",
    "Because the model is a bit complicated we'll import some of the code to keep the nortebook managable, showing you the important parts: we'll introduce the data format used by the model and load up a pretrained model that achieves state of the art results on the\n",
    "WMT 2014 English-German dataset.\n",
    "Finally we will show how to evaluate the model\n",
    "and translate a few sentences ourselves with the `BeamSearchTranslator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:41.474287Z",
     "start_time": "2018-08-20T10:19:39.109049Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "import gluonnlp as nlp\n",
    "import nmt\n",
    "\n",
    "ctx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pretrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "GluonNLP provides pretrained models for many standard architectures.\n",
    "First, let's retrieve a model pretrained on the WMT2014 English-to-German task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:33:14.738191Z",
     "start_time": "2018-08-20T10:33:12.961708Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "transformer_model, src_vocab, tgt_vocab = nmt.transformer.get_model(\n",
    "    'transformer_en_de_512',\n",
    "    dataset_name='WMT2014',\n",
    "    pretrained=True,\n",
    "    ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:40:40.904682Z",
     "start_time": "2018-08-20T10:40:40.901498Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=36794, unk=\"<unk>\", reserved=\"['<eos>', '<bos>', '<eos>']\")\n",
      "Vocab(size=36794, unk=\"<unk>\", reserved=\"['<eos>', '<bos>', '<eos>']\")\n"
     ]
    }
   ],
   "source": [
    "print(src_vocab)\n",
    "print(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:41:22.448079Z",
     "start_time": "2018-08-20T10:41:22.442131Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (1): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (2): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (3): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (4): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (5): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (1): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (2): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (3): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (4): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (5): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (src_embed): HybridSequential(\n",
      "    (0): Embedding(36794 -> 512, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (tgt_embed): HybridSequential(\n",
      "    (0): Embedding(36794 -> 512, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (tgt_proj): Dense(512 -> 36794, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The following shows how to process the dataset.\n",
    "The processing steps include:\n",
    "\n",
    "1. clip the source and target sequences\n",
    "2. split the string input to a list of tokens\n",
    "3. map the string token into its index in the vocabulary\n",
    "4. append EOS token to source sentence and add BOS and EOS tokens to target sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's first look at the WMT 2014 corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.306127Z",
     "start_time": "2018-08-20T10:19:41.480423Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "src_lang, tgt_lang = 'en', 'de'\n",
    "data_test = nlp.data.WMT2014BPE('newstest2014', src_lang=src_lang, tgt_lang=tgt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.317403Z",
     "start_time": "2018-08-20T10:19:55.307971Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Or@@ land@@ o Blo@@ om and Mir@@ anda Ker@@ r still love each other',\n",
       " 'Or@@ land@@ o Blo@@ om und Mir@@ anda Ker@@ r lieben sich noch immer')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.602066Z",
     "start_time": "2018-08-20T10:19:55.319120Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Orlando Bloom and Miranda Kerr still love each other',\n",
       " 'Orlando Bloom und Miranda Kerr lieben sich noch immer')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = nlp.data.WMT2014('newstest2014', src_lang=src_lang, tgt_lang=tgt_lang)\n",
    "test_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:45:35.615559Z",
     "start_time": "2018-08-20T10:45:35.612093Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform the machine translation dataset.\n",
      "\n",
      "    Clip source and the target sentences to the maximum length. For the source sentence, append the\n",
      "    EOS. For the target sentence, append BOS and EOS.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    src_vocab : Vocab\n",
      "    tgt_vocab : Vocab\n",
      "    src_max_len : int\n",
      "    tgt_max_len : int\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import dataprocessor\n",
    "\n",
    "print(dataprocessor.TrainValDataTransform.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:48:40.023539Z",
     "start_time": "2018-08-20T10:48:39.872442Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7300 21964 23833  1935 24004 11836  6698 11839  5565 25464 27950 22544\n",
      " 16202 24272     3]\n",
      "[    2  7300 21964 23833  1935 24004 29615  6698 11839  5565 25464 22297\n",
      " 27121 23712 20558     3]\n"
     ]
    }
   ],
   "source": [
    "transform_fn = dataprocessor.TrainValDataTransform(src_vocab, tgt_vocab, -1, -1)\n",
    "dataset_processed = data_test.transform(transform_fn, lazy=False)\n",
    "print(*dataset_processed[0], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sampler and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.811314Z",
     "start_time": "2018-08-20T10:19:55.806592Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_test_with_len = gluon.data.SimpleDataset([(ele[0], ele[1], len(\n",
    "    ele[0]), len(ele[1]), i) for i, ele in enumerate(dataset_processed)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, we have obtained `data_train`, `data_val`, and `data_test`. The next step\n",
    "is to construct sampler and DataLoader. The first step is to construct batchify\n",
    "function, which pads and stacks sequences to form mini-batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.816407Z",
     "start_time": "2018-08-20T10:19:55.812942Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_batchify_fn = nlp.data.batchify.Tuple(\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Pad(),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack(dtype='float32'),\n",
    "    nlp.data.batchify.Stack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We can then construct bucketing samplers, which generate batches by grouping\n",
    "sequences with similar lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.823596Z",
     "start_time": "2018-08-20T10:19:55.818052Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bucket_scheme = nlp.data.ExpWidthBucket(bucket_len_step=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.836751Z",
     "start_time": "2018-08-20T10:19:55.825234Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_batch_sampler = nlp.data.FixedBucketSampler(\n",
    "    lengths=dataset_processed.transform(lambda src, tgt: len(tgt)),\n",
    "    use_average_length=True,\n",
    "    bucket_scheme=bucket_scheme,\n",
    "    batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.840950Z",
     "start_time": "2018-08-20T10:19:55.838512Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FixedBucketSampler:\n",
      "  sample_num=2737, batch_num=364\n",
      "  key=[10, 14, 19, 25, 33, 42, 53, 66, 81, 100]\n",
      "  cnt=[101, 243, 386, 484, 570, 451, 280, 172, 41, 9]\n",
      "  batch_size=[25, 18, 13, 10, 8, 6, 5, 4, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(test_batch_sampler.stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Given the samplers, we can create DataLoader, which is iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:55.846728Z",
     "start_time": "2018-08-20T10:19:55.842645Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_loader = gluon.data.DataLoader(\n",
    "    data_test_with_len,\n",
    "    batch_sampler=test_batch_sampler,\n",
    "    batchify_fn=test_batchify_fn,\n",
    "    num_workers=8)\n",
    "len(test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pretrained Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Next, we will load the pretrained state of the art (SOTA) Transformer using the model API in GluonNLP.\n",
    "In this way, we can easily get access to the SOTA machine translation model and use it in your own application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:59.953069Z",
     "start_time": "2018-08-20T10:19:55.848334Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:59.957992Z",
     "start_time": "2018-08-20T10:19:59.955151Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=36794, unk=\"<unk>\", reserved=\"['<eos>', '<bos>', '<eos>']\")\n",
      "Vocab(size=36794, unk=\"<unk>\", reserved=\"['<eos>', '<bos>', '<eos>']\")\n"
     ]
    }
   ],
   "source": [
    "print(src_vocab)\n",
    "print(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:59.965583Z",
     "start_time": "2018-08-20T10:19:59.959612Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (1): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (2): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (3): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (4): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (5): TransformerEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (1): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (2): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (3): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (4): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "      (5): TransformerDecoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell_in): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (attention_cell_inter): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(512 -> 512, linear)\n",
      "          (proj_key): Dense(512 -> 512, linear)\n",
      "          (proj_value): Dense(512 -> 512, linear)\n",
      "        )\n",
      "        (proj_in): Dense(512 -> 512, linear)\n",
      "        (proj_inter): Dense(512 -> 512, linear)\n",
      "        (ffn): PositionwiseFFN(\n",
      "          (ffn_1): Dense(512 -> 2048, Activation(relu))\n",
      "          (ffn_2): Dense(2048 -> 512, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        )\n",
      "        (layer_norm_in): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "        (layer_norm_inter): LayerNorm(eps=1e-05, axis=-1, center=True, scale=True, in_channels=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (src_embed): HybridSequential(\n",
      "    (0): Embedding(36794 -> 512, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (tgt_embed): HybridSequential(\n",
      "    (0): Embedding(36794 -> 512, float32)\n",
      "    (1): Dropout(p = 0.0, axes=())\n",
      "  )\n",
      "  (tgt_proj): Dense(512 -> 36794, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transformer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Next, we will generate the SOTA results on validation and test datasets respectively. For ease of illustration, we only show the loss on the TOY validation and test datasets. To be able to obtain the SOTA results, please set the `demo=False`, and we are able to achieve 27.09 as the BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:59.970336Z",
     "start_time": "2018-08-20T10:19:59.967217Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "translator = nmt.translation.BeamSearchTranslator(\n",
    "    model=transformer_model,\n",
    "    beam_size=4,\n",
    "    scorer=nlp.model.BeamSearchScorer(alpha=0.6, K=5),\n",
    "    max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:19:59.975568Z",
     "start_time": "2018-08-20T10:19:59.971934Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_loss_function = nmt.loss.SoftmaxCEMaskedLoss()\n",
    "test_loss_function.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:20:00.447883Z",
     "start_time": "2018-08-20T10:19:59.977109Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "detokenizer = nlp.data.SacreMosesDetokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T10:26:48.493167Z",
     "start_time": "2018-08-20T10:20:00.449611Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model test loss 1.21\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "test_loss, _ = utils.evaluate(transformer_model, test_data_loader,\n",
    "                              test_loss_function, translator, tgt_vocab,\n",
    "                              detokenizer, ctx)\n",
    "\n",
    "print('Pretrained model test loss %.2f' % (test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- We showcased the Transformer, a powerful deep neural network approach to sequnce transduction (seq2seq) tasks. We showed you how to access a pretrained model in Gluon that matches SOTA results on the WMT 2014 English-German task.\n",
    "- The Gluon NLP Toolkit provides high-level APIs that could drastically simplify the development process of modeling for NLP tasks sharing the encoder-decoder structure.\n",
    "- The low-level APIs in the GluonNLP Toolkit makes it easy to customize these models.\n",
    "\n",
    "Documentation can be found at http://gluon-nlp.mxnet.io/index.html\n",
    "\n",
    "Code is here https://github.com/dmlc/gluon-nlp\n",
    "\n",
    "## References\n",
    "\n",
    "[1] Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in Neural Information Processing Systems. 2017."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
